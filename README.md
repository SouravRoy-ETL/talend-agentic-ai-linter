# ğŸ§  Talend AI Code Quality Framework

This project automates detection and fixing of Talend job design issues using YAML-based rules, `.item` job files, and OpenRouter LLMs (GPT-based). It supports zipped jobs, generates CSV reports, and shows beautifully formatted CLI output.

---

## ğŸ¥ Demo Video

[![Watch the Demo](https://img.youtube.com/vi/H0oVfQjiWkk/maxresdefault.jpg)](https://youtu.be/H0oVfQjiWkk)

> See the full agentic Talend LLM quality fixer in action!

## âœ… 50+ Production-Grade Code Quality Checks

This framework supports **50+ scalable, production-level rule checks** tailored for enterprise Talend pipelines.  
These cover:

- ğŸ” Context misuse & variable scope
- ğŸ§± Schema issues, nulls, and defaults
- ğŸš¨ Missing error handling (e.g., tDie, tWarn)
- ğŸª Unused metadata & dead code
- ğŸŒ€ Infinite loop detection & unsafe joins
- ğŸ¯ Naming conventions, error propagation, subjob limits, and more

> All rules are YAML-defined and support both `auto` fix and LLM-assisted suggestions.


## ğŸš€ How to Run

1. **Place your zipped Talend Jobs** into:

```
zipped_jobs/
```

2. **Run the full pipeline (after placing your real zipped Talend jobs inside `zipped_jobs/`):**

```bash
python talend_AgenticAI_SouraV1.py --verbose
```

This will:
- âœ… Validate rule YAMLs
- âœ… Extract `.item` files to `jobs/` from nested zips
- âœ… Lint and optionally auto-fix violations
- âœ… Query LLM for unresolved issues
- âœ… Save results to `fixed/` and `reports/fix_summary_report.csv`

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ talend_AgenticAI_SouraV1.py              # Main orchestrator script
â”œâ”€â”€ extract_items_with_delay.py     # Extracts `.item` files from zipped_jobs/
â”œâ”€â”€ validate_syntax.py              # Checks YAML rule format
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                     # Linting and fixing engine
â”‚   â””â”€â”€ llm.py                      # LLM handler via OpenRouter API
â”œâ”€â”€ rules/                          # YAML rules for code quality
â”œâ”€â”€ zipped_jobs/                    # Input zipped Talend exports
â”œâ”€â”€ jobs/                           # Extracted .item files
â”œâ”€â”€ fixed/                          # Auto-fixed jobs
â””â”€â”€ reports/
    â””â”€â”€ fix_summary_report.csv      # CSV summary
```

---

## ğŸ¤– LLM Integration

- **Provider:** OpenRouter.ai
- **Model:** GPT-3.5-Turbo
- **Prompt Example:**  
  `"Fix violation: {rule description}"`
- **Fallback:** Printed clearly in CLI if LLM fails
- **Confidence Score:** Low/Medium/High based on length

---

## ğŸ“¦ .item Job Extraction Logic

- Looks inside each `zipped_jobs/*.zip`
- Recursively searches folders for `process/` directory
- Copies `.item` files to `jobs/`
- Adds delay of 1.1s per extraction
- Logs each job as:
  ```
  âœ… Extracted job: myJob_0.1.item
  ```

---

## ğŸ“Š CSV Report Format

| job_file      | rule_id | status        | llm_suggestion                            | confidence |
|---------------|---------|----------------|-------------------------------------------|------------|
| myJob.item    | RULE_036 | llm-suggested | Defaults in schema don't match data type | medium     |
| myJob2.item   | RULE_028 | fixed          |                                           | 1.0        |

---

## ğŸ§  Features

- ğŸ’¬ GPT suggestions for unresolved issues
- ğŸ›  Auto-fix for rules with `"strategy: auto"`
- ğŸ”„ Caching of LLM responses
- ğŸ¢ 1.1s throttled file extraction
- ğŸ“‹ Emoji-decorated CLI
- ğŸ§ª YAML rule format validation

---

## ğŸ§° Requirements

- Python 3.9+
- `pip install -r requirements.txt` with:
  - `openai>=1.0.0`
  - `python-dotenv`
  - `PyYAML`

---

## ğŸ’¡ Future Ideas

- [ ] Rule-specific enable/disable
- [ ] GUI dashboard for job summaries
- [ ] Email report delivery
- [ ] `.env` setup wizard

---


---


## ğŸ” OpenRouter API Key Setup

1. Visit [https://openrouter.ai/](https://openrouter.ai/)
2. Sign in and generate an API key from:  
   [https://openrouter.ai/keys](https://openrouter.ai/keys)
3. Copy the API key (starts with `sk-or-...`)

4. Create a `.env` file in your project root with:
```
OPENROUTER_API_KEY=sk-or-your-key-here
```

5. Make sure `python-dotenv` is installed:
```
pip install python-dotenv
```

This allows `llm.py` to securely load your OpenRouter key at runtime.


---


